{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import numpy as np\n",
    "import shutil, random, os, sys, torch\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prj_dir = os.path.dirname(os.path.abspath(__file__)) # for script\n",
    "prj_dir = os.path.dirname(os.path.abspath(\"\")) # for jupyter\n",
    "sys.path.append(prj_dir)\n",
    "\n",
    "from modules.utils import load_yaml, get_logger\n",
    "from modules.metrics import get_metric_function\n",
    "from modules.earlystoppers import EarlyStopper\n",
    "from modules.losses import get_loss_function\n",
    "from modules.optimizers import get_optimizer\n",
    "from modules.schedulers import get_scheduler\n",
    "from modules.scalers import get_image_scaler\n",
    "from modules.datasets import SegDataset\n",
    "from modules.recorders import Recorder\n",
    "from modules.trainer import Trainer\n",
    "from models.utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_dir = os.path.dirname(os.path.abspath(\"baseline\")) # for jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Dev\\\\2022\\\\maicon\\\\baseline'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = 'train.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = os.path.join(prj_dir, 'config', yaml)\n",
    "config = load_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\2022\\maicon\\baseline\\trian.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Set train serial: ex) 20211004\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_serial \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_serial \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m train_serial\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Set random seed, deterministic\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmanual_seed(config[\u001b[39m'\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set train serial: ex) 20211004\n",
    "train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_serial = 'debug' if config['debug'] else train_serial\n",
    "\n",
    "# Set random seed, deterministic\n",
    "torch.cuda.manual_seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device(GPU/CPU)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_num'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create train result directory and set logger\n",
    "train_result_dir = os.path.join(prj_dir, 'results', 'train', train_serial)\n",
    "os.makedirs(train_result_dir, exist_ok=True)\n",
    "\n",
    "# Set logger\n",
    "logging_level = 'debug' if config['verbose'] else 'info'\n",
    "logger = get_logger(name='train',\n",
    "                    file_path=os.path.join(train_result_dir, 'train.log'),\n",
    "                    level=logging_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "train_dirs = os.path.join(prj_dir, 'data', 'train')\n",
    "\n",
    "# Load data and create dataset for train \n",
    "# Load image scaler\n",
    "train_img_paths = glob(os.path.join(train_dirs, 'x', '*.png'))\n",
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=config['val_size'], random_state=config['seed'], shuffle=True)\n",
    "\n",
    "train_dataset = SegDataset(paths=train_img_paths,\n",
    "                        input_size=[config['input_width'], config['input_height']],\n",
    "                        scaler=get_image_scaler(config['scaler']),\n",
    "                        logger=None)\n",
    "val_dataset = SegDataset(paths=val_img_paths,\n",
    "                        input_size=[config['input_width'], config['input_height']],\n",
    "                        scaler=get_image_scaler(config['scaler']),\n",
    "                        logger=None)\n",
    "# Create data loader\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=config['shuffle'],\n",
    "                            drop_last=config['drop_last'])\n",
    "                            \n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=False,\n",
    "                            drop_last=config['drop_last'])\n",
    "\n",
    "# logger.info(f\"Load dataset, train: {len(train_dataset)}, val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Opimizer, Scheduler, Loss and etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = get_model(model_str=config['architecture'])\n",
    "model = model(classes=config['n_classes'],\n",
    "            encoder_name=config['encoder'],\n",
    "            encoder_weights=config['encoder_weight'],\n",
    "            activation=config['activation']).to(device)\n",
    "logger.info(f\"Load model architecture: {config['architecture']}\")\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = get_optimizer(optimizer_str=config['optimizer']['name'])\n",
    "optimizer = optimizer(model.parameters(), **config['optimizer']['args'])\n",
    "\n",
    "# Set Scheduler\n",
    "scheduler = get_scheduler(scheduler_str=config['scheduler']['name'])\n",
    "scheduler = scheduler(optimizer=optimizer, **config['scheduler']['args'])\n",
    "\n",
    "# Set loss function\n",
    "loss_func = get_loss_function(loss_function_str=config['loss']['name'])\n",
    "loss_func = loss_func(**config['loss']['args'])\n",
    "\n",
    "# Set metric\n",
    "metric_funcs = {metric_name:get_metric_function(metric_name) for metric_name in config['metrics']}\n",
    "logger.info(f\"Load optimizer:{config['optimizer']['name']}, scheduler: {config['scheduler']['name']}, loss: {config['loss']['name']}, metric: {config['metrics']}\")\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(model=model,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                loss_func=loss_func,\n",
    "                metric_funcs=metric_funcs,\n",
    "                device=device,\n",
    "                logger=logger)\n",
    "logger.info(f\"Load trainer\")\n",
    "\n",
    "# Set early stopper\n",
    "early_stopper = EarlyStopper(patience=config['earlystopping_patience'],\n",
    "                            logger=logger)\n",
    "# Set recorder\n",
    "recorder = Recorder(record_dir=train_result_dir,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    logger=logger)\n",
    "logger.info(\"Load early stopper, recorder\")\n",
    "\n",
    "# Recorder - save train config\n",
    "shutil.copy(config_path, os.path.join(recorder.record_dir, yaml))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 1 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "Epoch 0/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:45<00:00, 15.18s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:44<00:00, 15.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:40<00:00, 15.17s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:40<00:00, 15.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:30:58<00:00, 15.10s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:43<00:00, 15.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:15<00:00, 15.13s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:40<00:00, 15.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:07<00:00, 15.11s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:41<00:00, 15.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:30:50<00:00, 15.08s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:41<00:00, 15.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:08<00:00, 15.11s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:43<00:00, 15.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [2:31:10<00:00, 15.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [37:44<00:00, 15.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/600 [03:13<2:26:48, 14.98s/it]"
     ]
    }
   ],
   "source": [
    "architectures = ['PAN', 'Linknet', 'FPN',\n",
    "                 'DeepLabV3Plus', 'DeepLabV3', 'Unet', 'UnetPlusPlus',\n",
    "                 'PSPNet', 'MAnet',]\n",
    "for architecture in architectures:\n",
    "    #----\n",
    "    # Load config\n",
    "    config_path = os.path.join(prj_dir, 'config', \"train_\"+architecture+\".yaml\")\n",
    "    config = load_yaml(config_path)\n",
    "\n",
    "    # Set train serial: ex) 20211004\n",
    "    train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    train_serial = 'debug' if config['debug'] else train_serial\n",
    "\n",
    "    # Set random seed, deterministic\n",
    "    torch.cuda.manual_seed(config['seed'])\n",
    "    torch.manual_seed(config['seed'])\n",
    "    np.random.seed(config['seed'])\n",
    "    random.seed(config['seed'])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set device(GPU/CPU)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_num'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Create train result directory and set logger\n",
    "    train_result_dir = os.path.join(prj_dir, 'results', 'train', architecture, train_serial)\n",
    "    os.makedirs(train_result_dir, exist_ok=True)\n",
    "\n",
    "    # Set logger\n",
    "    logging_level = 'debug' if config['verbose'] else 'info'\n",
    "    logger = get_logger(name='train',\n",
    "                        file_path=os.path.join(train_result_dir, 'train.log'),\n",
    "                        level=logging_level)\n",
    "\n",
    "    #----\n",
    "    # Load model\n",
    "    model = get_model(model_str=config['architecture'])\n",
    "    model = model(classes=config['n_classes'],\n",
    "                encoder_name=config['encoder'],\n",
    "                encoder_weights=config['encoder_weight'],\n",
    "                activation=config['activation']).to(device)\n",
    "    logger.info(f\"Load model architecture: {config['architecture']}\")\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = get_optimizer(optimizer_str=config['optimizer']['name'])\n",
    "    optimizer = optimizer(model.parameters(), **config['optimizer']['args'])\n",
    "\n",
    "    # Set Scheduler\n",
    "    scheduler = get_scheduler(scheduler_str=config['scheduler']['name'])\n",
    "    scheduler = scheduler(optimizer=optimizer, **config['scheduler']['args'])\n",
    "\n",
    "    # Set loss function\n",
    "    loss_func = get_loss_function(loss_function_str=config['loss']['name'])\n",
    "    loss_func = loss_func(**config['loss']['args'])\n",
    "\n",
    "    # Set metric\n",
    "    metric_funcs = {metric_name:get_metric_function(metric_name) for metric_name in config['metrics']}\n",
    "    logger.info(f\"Load optimizer:{config['optimizer']['name']}, scheduler: {config['scheduler']['name']}, loss: {config['loss']['name']}, metric: {config['metrics']}\")\n",
    "\n",
    "    # Set trainer\n",
    "    trainer = Trainer(model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    loss_func=loss_func,\n",
    "                    metric_funcs=metric_funcs,\n",
    "                    device=device,\n",
    "                    logger=logger)\n",
    "    logger.info(f\"Load trainer\")\n",
    "\n",
    "    # Set early stopper\n",
    "    early_stopper = EarlyStopper(patience=config['earlystopping_patience'],\n",
    "                                logger=logger)\n",
    "    # Set recorder\n",
    "    recorder = Recorder(record_dir=train_result_dir,\n",
    "                        model=model,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        logger=logger)\n",
    "    logger.info(\"Load early stopper, recorder\")\n",
    "\n",
    "    # Recorder - save train config\n",
    "    shutil.copy(config_path, os.path.join(recorder.record_dir, yaml))\n",
    "\n",
    "    #----\n",
    "    # Train\n",
    "    print(\"START TRAINING\")\n",
    "    logger.info(\"START TRAINING\")\n",
    "    for epoch_id in range(config['n_epochs']):\n",
    "        \n",
    "        # Initiate result row\n",
    "        row = dict()\n",
    "        row['epoch_id'] = epoch_id\n",
    "        row['train_serial'] = train_serial\n",
    "        row['lr'] = trainer.scheduler.get_last_lr()\n",
    "\n",
    "        # Train\n",
    "        print(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "        logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "        tic = time()\n",
    "        trainer.train(dataloader=train_dataloader, epoch_index=epoch_id)\n",
    "        toc = time()\n",
    "        # Write tarin result to result row\n",
    "        row['train_loss'] = trainer.loss  # Loss\n",
    "        for metric_name, metric_score in trainer.scores.items():\n",
    "            row[f'train_{metric_name}'] = metric_score\n",
    "\n",
    "        row['train_elapsed_time'] = round(toc-tic, 1)\n",
    "        # Clear\n",
    "        trainer.clear_history()\n",
    "\n",
    "        # Validation\n",
    "        print(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "        logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "        tic = time()\n",
    "        trainer.validate(dataloader=val_dataloader, epoch_index=epoch_id)\n",
    "        toc = time()\n",
    "        row['val_loss'] = trainer.loss\n",
    "        # row[f\"val_{config['metric']}\"] = trainer.score\n",
    "        for metric_name, metric_score in trainer.scores.items():\n",
    "            row[f'val_{metric_name}'] = metric_score\n",
    "        row['val_elapsed_time'] = round(toc-tic, 1)\n",
    "        trainer.clear_history()\n",
    "\n",
    "        # Performance record - row\n",
    "        recorder.add_row(row)\n",
    "        \n",
    "        # Performance record - plot\n",
    "        recorder.save_plot(config['plot'])\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopper.check_early_stopping(row[config['earlystopping_target']])\n",
    "        if early_stopper.patience_counter == 0:\n",
    "            recorder.save_weight(epoch=epoch_id)\n",
    "            \n",
    "        if early_stopper.stop:\n",
    "            print(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "            logger.info(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "            break\n",
    "\n",
    "    print(\"END TRAINING\")\n",
    "    logger.info(\"END TRAINING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4755a0ac336b2d92cae304601054584f3e51fa9cdaefb452a7f1602e63829cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
