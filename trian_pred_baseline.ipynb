{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import numpy as np\n",
    "import shutil, random, os, sys, torch\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prj_dir = os.path.dirname(os.path.abspath(__file__)) # for script\n",
    "prj_dir = os.path.dirname(os.path.abspath(\"\")) # for jupyter\n",
    "sys.path.append(prj_dir)\n",
    "\n",
    "from modules.utils import load_yaml, get_logger\n",
    "from modules.metrics import get_metric_function\n",
    "from modules.earlystoppers import EarlyStopper\n",
    "from modules.losses import get_loss_function\n",
    "from modules.optimizers import get_optimizer\n",
    "from modules.schedulers import get_scheduler\n",
    "from modules.scalers import get_image_scaler\n",
    "from modules.datasets import SegDataset\n",
    "from modules.recorders import Recorder\n",
    "from modules.trainer import Trainer\n",
    "from models.utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_dir = os.path.dirname(os.path.abspath(\"baseline\")) # for jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Dev\\\\2022\\\\maicon\\\\baseline'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = 'train.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = os.path.join(prj_dir, 'config', yaml)\n",
    "config = load_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Set train serial: ex) 20211004\n",
    "# train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# train_serial = 'debug' if config['debug'] else train_serial\n",
    "\n",
    "# # Set random seed, deterministic\n",
    "# torch.cuda.manual_seed(config['seed'])\n",
    "# torch.manual_seed(config['seed'])\n",
    "# np.random.seed(config['seed'])\n",
    "# random.seed(config['seed'])\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# # Set device(GPU/CPU)\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_num'])\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Create train result directory and set logger\n",
    "# train_result_dir = os.path.join(prj_dir, 'results', 'train', train_serial)\n",
    "# os.makedirs(train_result_dir, exist_ok=True)\n",
    "\n",
    "# # Set logger\n",
    "# logging_level = 'debug' if config['verbose'] else 'info'\n",
    "# logger = get_logger(name='train',\n",
    "#                     file_path=os.path.join(train_result_dir, 'train.log'),\n",
    "#                     level=logging_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "train_dirs = os.path.join(prj_dir, 'data', 'train')\n",
    "\n",
    "# Load data and create dataset for train \n",
    "# Load image scaler\n",
    "train_img_paths = glob(os.path.join(train_dirs, 'x', '*.png'))\n",
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=config['val_size'], random_state=config['seed'], shuffle=True)\n",
    "\n",
    "train_dataset = SegDataset(paths=train_img_paths,\n",
    "                        input_size=[config['input_width'], config['input_height']],\n",
    "                        scaler=get_image_scaler(config['scaler']),\n",
    "                        logger=None)\n",
    "val_dataset = SegDataset(paths=val_img_paths,\n",
    "                        input_size=[config['input_width'], config['input_height']],\n",
    "                        scaler=get_image_scaler(config['scaler']),\n",
    "                        logger=None)\n",
    "# Create data loader\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=config['shuffle'],\n",
    "                            drop_last=config['drop_last'])\n",
    "                            \n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=False,\n",
    "                            drop_last=config['drop_last'])\n",
    "\n",
    "# logger.info(f\"Load dataset, train: {len(train_dataset)}, val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n",
      "torch.Size([8, 3, 336, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\2022\\maicon\\baseline\\trian_multi.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, (x,y,filename) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1206\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1207\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1173\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1174\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1175\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m    999\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1012\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1013\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1014\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    885\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    817\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_id, (x,y,filename) in enumerate(train_dataloader):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Opimizer, Scheduler, Loss and etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# model = get_model(model_str=config['architecture'])\n",
    "# model = model(classes=config['n_classes'],\n",
    "#             encoder_name=config['encoder'],\n",
    "#             encoder_weights=config['encoder_weight'],\n",
    "#             activation=config['activation']).to(device)\n",
    "# logger.info(f\"Load model architecture: {config['architecture']}\")\n",
    "\n",
    "# # Set optimizer\n",
    "# optimizer = get_optimizer(optimizer_str=config['optimizer']['name'])\n",
    "# optimizer = optimizer(model.parameters(), **config['optimizer']['args'])\n",
    "\n",
    "# # Set Scheduler\n",
    "# scheduler = get_scheduler(scheduler_str=config['scheduler']['name'])\n",
    "# scheduler = scheduler(optimizer=optimizer, **config['scheduler']['args'])\n",
    "\n",
    "# # Set loss function\n",
    "# loss_func = get_loss_function(loss_function_str=config['loss']['name'])\n",
    "# loss_func = loss_func(**config['loss']['args'])\n",
    "\n",
    "# # Set metric\n",
    "# metric_funcs = {metric_name:get_metric_function(metric_name) for metric_name in config['metrics']}\n",
    "# logger.info(f\"Load optimizer:{config['optimizer']['name']}, scheduler: {config['scheduler']['name']}, loss: {config['loss']['name']}, metric: {config['metrics']}\")\n",
    "\n",
    "# # Set trainer\n",
    "# trainer = Trainer(model=model,\n",
    "#                 optimizer=optimizer,\n",
    "#                 scheduler=scheduler,\n",
    "#                 loss_func=loss_func,\n",
    "#                 metric_funcs=metric_funcs,\n",
    "#                 device=device,\n",
    "#                 logger=logger)\n",
    "# logger.info(f\"Load trainer\")\n",
    "\n",
    "# # Set early stopper\n",
    "# early_stopper = EarlyStopper(patience=config['earlystopping_patience'],\n",
    "#                             logger=logger)\n",
    "# # Set recorder\n",
    "# recorder = Recorder(record_dir=train_result_dir,\n",
    "#                     model=model,\n",
    "#                     optimizer=optimizer,\n",
    "#                     scheduler=scheduler,\n",
    "#                     logger=logger)\n",
    "# logger.info(\"Load early stopper, recorder\")\n",
    "\n",
    "# # Recorder - save train config\n",
    "# shutil.copy(config_path, os.path.join(recorder.record_dir, yaml))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = os.path.join(prj_dir, 'config', \"train\"+\".yaml\")\n",
    "# config = load_yaml(config_path)\n",
    "# model = get_model(model_str=config['architecture'])\n",
    "# model = model(classes=config['n_classes'],\n",
    "#             encoder_name=config['encoder'],\n",
    "#             encoder_weights=config['encoder_weight'],\n",
    "#             activation=config['activation'])\n",
    "# check_point_path = os.path.join(prj_dir, 'results', 'train','20221113_010847', 'model.pt')\n",
    "# check_point = torch.load(check_point_path)\n",
    "# model.load_state_dict(check_point['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi\n",
      "START TRAINING\n",
      "Epoch 0/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:48:45<00:00, 10.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:43<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:59<00:00, 10.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:56<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:52:20<00:00, 10.33s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:42<00:00,  9.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:50:09<00:00, 10.23s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:02<00:00, 10.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:37<00:00, 10.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:59<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:42<00:00, 10.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:48<00:00,  9.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:54<00:00, 10.22s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:54<00:00,  9.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:58<00:00, 10.22s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:52<00:00,  9.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:50:53<00:00, 10.26s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:02<00:00, 10.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:19<00:00, 10.19s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:01<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:48:57<00:00, 10.18s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:13<00:00, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:45<00:00, 10.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:09<00:00, 10.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:34<00:00, 10.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:09<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:50:06<00:00, 10.23s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:00<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:55<00:00, 10.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:42<00:00,  9.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:48<00:00, 10.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:52<00:00,  9.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:51:17<00:00, 10.28s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:09<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:31<00:00, 10.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:15<00:00, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:47<00:00, 10.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:10<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:50:43<00:00, 10.25s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [25:21<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:59<00:00, 10.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:58<00:00,  9.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████| 1350/1350 [3:49:11<00:00, 10.19s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [24:57<00:00,  9.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1350 [00:00<?, ?it/s]c:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "  4%|▍         | 59/1350 [10:21<3:46:33, 10.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\2022\\maicon\\baseline\\trian_multi.ipynb 셀 15\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X20sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mconfig[\u001b[39m'\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m Train..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X20sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X20sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, epoch_index\u001b[39m=\u001b[39;49mepoch_id)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X20sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m toc \u001b[39m=\u001b[39m time()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Dev/2022/maicon/baseline/trian_multi.ipynb#X20sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Write tarin result to result row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Dev\\2022\\maicon\\baseline\\modules\\trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, dataloader, epoch_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m     54\u001b[0m \u001b[39m# Loss\u001b[39;00m\n\u001b[0;32m     55\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_func(y_pred, y)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[0;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[1;32m--> 168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[0;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py:78\u001b[0m, in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     76\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     77\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[1;32m---> 78\u001b[0m         thread\u001b[39m.\u001b[39mjoin()\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\threading.py:1089\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1090\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1091\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310_pytorch\\lib\\threading.py:1109\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1110\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1111\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# architectures = ['DeepLabV3Plus']\n",
    "# for architecture in architectures:\n",
    "#----\n",
    "# Load config\n",
    "# config_path = os.path.join(prj_dir, 'config', \"train\"+\".yaml\")\n",
    "# config = load_yaml(config_path)\n",
    "\n",
    "# Set train serial: ex) 20211004\n",
    "train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_serial = 'debug' if config['debug'] else train_serial\n",
    "\n",
    "# Set random seed, deterministic\n",
    "torch.cuda.manual_seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device(GPU/CPU)\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_num'])\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create train result directory and set logger\n",
    "# train_result_dir = os.path.join(prj_dir, 'results', 'train', architecture, train_serial)\n",
    "train_result_dir = os.path.join(prj_dir, 'results', 'train', train_serial)\n",
    "os.makedirs(train_result_dir, exist_ok=True)\n",
    "\n",
    "# Set logger\n",
    "logging_level = 'debug' if config['verbose'] else 'info'\n",
    "logger = get_logger(name='train',\n",
    "                    file_path=os.path.join(train_result_dir, 'train.log'),\n",
    "                    level=logging_level)\n",
    "\n",
    "#----\n",
    "# Load model\n",
    "# model = get_model(model_str=config['architecture'])\n",
    "# model = model(classes=config['n_classes'],\n",
    "#             encoder_name=config['encoder'],\n",
    "#             encoder_weights=config['encoder_weight'],\n",
    "#             activation=config['activation'])\n",
    "# check_point_path = os.path.join(prj_dir, 'results', 'train', 'DeepLabV3Plus','20221112_222652', 'model.pt')\n",
    "# check_point = torch.load(check_point_path)\n",
    "# model.load_state_dict(check_point['model'])\n",
    "# config_path = os.path.join(prj_dir, 'config', \"train\"+\".yaml\")\n",
    "# config = load_yaml(config_path)\n",
    "model = get_model(model_str=config['architecture'])\n",
    "model = model(classes=config['n_classes'],\n",
    "            encoder_name=config['encoder'],\n",
    "            encoder_weights=config['encoder_weight'],\n",
    "            activation=config['activation'])\n",
    "# check_point_path = os.path.join(prj_dir, 'results', 'train', 'DeepLabV3Plus','20221112_222652', 'model.pt')\n",
    "check_point_path = os.path.join(prj_dir, 'results', 'train', '20221116_173442', 'model.pt')\n",
    "check_point = torch.load(check_point_path)\n",
    "\n",
    "model_dict = check_point['model']\n",
    "keys = model_dict.keys()\n",
    "values = model_dict.values()\n",
    "new_keys = []\n",
    "\n",
    "for key in keys:\n",
    "  new_key = key[7:]    # remove the 'module.'\n",
    "  new_keys.append(new_key)\n",
    "new_dict = OrderedDict(list(zip(new_keys, values)))\n",
    "model.load_state_dict(new_dict)\n",
    "# model.load_state_dict(check_point['model'])\n",
    "logger.info(f\"Load model weight, {check_point_path}\")\n",
    "\n",
    "NGPU = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if NGPU > 1:\n",
    "    print(\"Multi\")\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(NGPU)))\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "model.to(device)\n",
    "logger.info(f\"Load model architecture: {config['architecture']}\")\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = get_optimizer(optimizer_str=config['optimizer']['name'])\n",
    "optimizer = optimizer(model.parameters(), **config['optimizer']['args'])\n",
    "\n",
    "# Set Scheduler\n",
    "scheduler = get_scheduler(scheduler_str=config['scheduler']['name'])\n",
    "scheduler = scheduler(optimizer=optimizer, **config['scheduler']['args'])\n",
    "\n",
    "# Set loss function\n",
    "loss_func = get_loss_function(loss_function_str=config['loss']['name'])\n",
    "loss_func = loss_func(**config['loss']['args'])\n",
    "\n",
    "# Set metric\n",
    "metric_funcs = {metric_name:get_metric_function(metric_name) for metric_name in config['metrics']}\n",
    "logger.info(f\"Load optimizer:{config['optimizer']['name']}, scheduler: {config['scheduler']['name']}, loss: {config['loss']['name']}, metric: {config['metrics']}\")\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(model=model,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                loss_func=loss_func,\n",
    "                metric_funcs=metric_funcs,\n",
    "                device=device,\n",
    "                logger=logger)\n",
    "logger.info(f\"Load trainer\")\n",
    "\n",
    "# Set early stopper\n",
    "early_stopper = EarlyStopper(patience=config['earlystopping_patience'],\n",
    "                            logger=logger)\n",
    "# Set recorder\n",
    "recorder = Recorder(record_dir=train_result_dir,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    logger=logger)\n",
    "logger.info(\"Load early stopper, recorder\")\n",
    "\n",
    "# Recorder - save train config\n",
    "shutil.copy(config_path, os.path.join(recorder.record_dir, yaml))\n",
    "\n",
    "#----\n",
    "# Train\n",
    "print(\"START TRAINING\")\n",
    "logger.info(\"START TRAINING\")\n",
    "for epoch_id in range(config['n_epochs']):\n",
    "    \n",
    "    # Initiate result row\n",
    "    row = dict()\n",
    "    row['epoch_id'] = epoch_id\n",
    "    row['train_serial'] = train_serial\n",
    "    row['lr'] = trainer.scheduler.get_last_lr()\n",
    "\n",
    "    # Train\n",
    "    print(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "    logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "    tic = time()\n",
    "    trainer.train(dataloader=train_dataloader, epoch_index=epoch_id)\n",
    "    toc = time()\n",
    "    # Write tarin result to result row\n",
    "    row['train_loss'] = trainer.loss  # Loss\n",
    "    for metric_name, metric_score in trainer.scores.items():\n",
    "        row[f'train_{metric_name}'] = metric_score\n",
    "\n",
    "    row['train_elapsed_time'] = round(toc-tic, 1)\n",
    "    # Clear\n",
    "    trainer.clear_history()\n",
    "\n",
    "    # Validation\n",
    "    print(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "    logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "    tic = time()\n",
    "    trainer.validate(dataloader=val_dataloader, epoch_index=epoch_id)\n",
    "    toc = time()\n",
    "    row['val_loss'] = trainer.loss\n",
    "    # row[f\"val_{config['metric']}\"] = trainer.score\n",
    "    for metric_name, metric_score in trainer.scores.items():\n",
    "        row[f'val_{metric_name}'] = metric_score\n",
    "    row['val_elapsed_time'] = round(toc-tic, 1)\n",
    "    trainer.clear_history()\n",
    "\n",
    "    # Performance record - row\n",
    "    recorder.add_row(row)\n",
    "    \n",
    "    # Performance record - plot\n",
    "    recorder.save_plot(config['plot'])\n",
    "\n",
    "    # Check early stopping\n",
    "    early_stopper.check_early_stopping(row[config['earlystopping_target']])\n",
    "    if early_stopper.patience_counter == 0:\n",
    "        recorder.save_weight(epoch=epoch_id)\n",
    "        \n",
    "    if early_stopper.stop:\n",
    "        print(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "        logger.info(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "        break\n",
    "\n",
    "print(\"END TRAINING\")\n",
    "logger.info(\"END TRAINING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [05:50<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import random, os, sys, torch, cv2, warnings\n",
    "# from glob import glob\n",
    "# from torch.utils.data import DataLoader\n",
    "#  # Create train result directory and set logger\n",
    "# pred_result_dir = os.path.join(prj_dir, 'results', 'pred', 'pred_serial')\n",
    "# pred_result_dir_mask = os.path.join(prj_dir, 'results', 'pred', 'pred_serial', 'mask')\n",
    "# os.makedirs(pred_result_dir, exist_ok=True)\n",
    "# os.makedirs(pred_result_dir_mask, exist_ok=True)\n",
    "\n",
    "# # Set logger\n",
    "# logging_level = 'debug' if config['verbose'] else 'info'\n",
    "# logger = get_logger(name='train',\n",
    "#                     file_path=os.path.join(pred_result_dir, 'pred.log'),\n",
    "#                     level=logging_level)\n",
    "\n",
    "# # Set data directory\n",
    "# test_dirs = os.path.join(prj_dir, 'data', 'test')\n",
    "# test_img_paths = glob(os.path.join(test_dirs, 'x', '*.png'))\n",
    "\n",
    "# #! Load data & create dataset for train \n",
    "# test_dataset = SegDataset(paths=test_img_paths,\n",
    "#                         input_size=[config['input_width'], config['input_height']],\n",
    "#                         scaler=get_image_scaler(config['scaler']),\n",
    "#                         mode='test',\n",
    "#                         logger=logger)\n",
    "\n",
    "# # Create data loader\n",
    "# test_dataloader = DataLoader(dataset=test_dataset,\n",
    "#                             batch_size=config['batch_size'],\n",
    "#                             num_workers=config['num_workers'],\n",
    "#                             shuffle=False,\n",
    "#                             drop_last=False)\n",
    "\n",
    "# # Predict\n",
    "# logger.info(f\"START PREDICTION\")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     for batch_id, (x, orig_size, filename) in enumerate(tqdm(test_dataloader)):\n",
    "        \n",
    "#         x = x.to(device, dtype=torch.float)\n",
    "#         y_pred = model(x)\n",
    "#         y_pred_argmax = y_pred.argmax(1).cpu().numpy().astype(np.uint8)\n",
    "#         orig_size = [(orig_size[0].tolist()[i], orig_size[1].tolist()[i]) for i in range(len(orig_size[0]))]\n",
    "#         # Save predict result\n",
    "#         for filename_, orig_size_, y_pred_ in zip(filename, orig_size, y_pred_argmax):\n",
    "#             resized_img = cv2.resize(y_pred_, [orig_size_[1], orig_size_[0]], interpolation=cv2.INTER_NEAREST)\n",
    "#             cv2.imwrite(os.path.join(pred_result_dir_mask, filename_), resized_img)\n",
    "# logger.info(f\"END PREDICTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4755a0ac336b2d92cae304601054584f3e51fa9cdaefb452a7f1602e63829cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
